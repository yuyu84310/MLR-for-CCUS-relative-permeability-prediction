{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "#### 1. Import packages",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport copy\nimport math\nimport pandas as pd",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "#### 2. Problem Statement\nThis work uses multiple linear regression to determine the dependent variable crosspoint saturation (CSw) of water and CO2 relative permeability curves from the irreducible water saturation (Swi) and true reference cross point saturation (RCS). The first independent variable Swi is a decimal that has the range of 0–1. To constrain this range, another variable true reference cross point saturation (RCS) is also introduced. RCS has physical meaning and is half of the dynamic space:\nRCS = 0.5 × (1 - Swi).\nThis project has limited data, PRB#1 data is for training and PRB#2 data is for testing.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### 3. Dataset\nThe training data is from the PRB#1 core samples relative permeability curves. First variable x(j=1) is Swi, and second x(j=2) is RCS. y is CS. There are eight samples from Lakota, Hulett, and Minnelusa formations.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv('CS_project.csv')\ntrain = df.iloc[0:8]\n# take a look at the dataset\ntrain",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         Sample No.       Swi  true RCS       CSw\n0     Lakota 8031.4  0.540999  0.229500  0.770701\n1     Lakota 8035.4  0.580368  0.209816  0.787591\n2     Hulett 8307.7  0.469720  0.265140  0.743720\n3     Hulett 8325.8  0.579942  0.210029  0.817819\n4     Hulett 8332.6  0.526892  0.236554  0.712748\n5  Minnelusa 9366.8  0.406033  0.296984  0.652225\n6  Minnelusa 9464.2  0.416358  0.291821  0.747614\n7  Minnelusa 9529.3  0.491233  0.254384  0.725876",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample No.</th>\n      <th>Swi</th>\n      <th>true RCS</th>\n      <th>CSw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Lakota 8031.4</td>\n      <td>0.540999</td>\n      <td>0.229500</td>\n      <td>0.770701</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lakota 8035.4</td>\n      <td>0.580368</td>\n      <td>0.209816</td>\n      <td>0.787591</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hulett 8307.7</td>\n      <td>0.469720</td>\n      <td>0.265140</td>\n      <td>0.743720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hulett 8325.8</td>\n      <td>0.579942</td>\n      <td>0.210029</td>\n      <td>0.817819</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hulett 8332.6</td>\n      <td>0.526892</td>\n      <td>0.236554</td>\n      <td>0.712748</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Minnelusa 9366.8</td>\n      <td>0.406033</td>\n      <td>0.296984</td>\n      <td>0.652225</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Minnelusa 9464.2</td>\n      <td>0.416358</td>\n      <td>0.291821</td>\n      <td>0.747614</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Minnelusa 9529.3</td>\n      <td>0.491233</td>\n      <td>0.254384</td>\n      <td>0.725876</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "X_train = np.asanyarray(train[['Swi', 'true RCS']])\n# asanyarray: Convert the input to an ndarray, but pass ndarray subclasses through.\nX_train",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.54099923, 0.22950038],\n       [0.58036782, 0.20981609],\n       [0.46972036, 0.26513982],\n       [0.5799417 , 0.21002915],\n       [0.52689179, 0.2365541 ],\n       [0.4060325 , 0.29698375],\n       [0.41635819, 0.2918209 ],\n       [0.49123282, 0.25438359]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "y_train = np.asanyarray(train[['CSw']])\ny_train",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.770701 ],\n       [0.787591 ],\n       [0.74372  ],\n       [0.817819 ],\n       [0.712748 ],\n       [0.652225 ],\n       [0.7476135],\n       [0.7258761]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "test = df.iloc[8:11]\ntest",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "          Sample No.       Swi  true RCS       CSw\n8        Lakota 8063  0.591990  0.204005  0.773270\n9        Hulett 8330  0.521616  0.239192  0.766865\n10  Minnelusa C 9487  0.409992  0.295004  0.681677",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sample No.</th>\n      <th>Swi</th>\n      <th>true RCS</th>\n      <th>CSw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>Lakota 8063</td>\n      <td>0.591990</td>\n      <td>0.204005</td>\n      <td>0.773270</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hulett 8330</td>\n      <td>0.521616</td>\n      <td>0.239192</td>\n      <td>0.766865</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Minnelusa C 9487</td>\n      <td>0.409992</td>\n      <td>0.295004</td>\n      <td>0.681677</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "X_test = np.asanyarray(test[['Swi', 'true RCS']])\nX_test",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.59198969, 0.20400515],\n       [0.52161571, 0.23919214],\n       [0.40999183, 0.29500408]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "y_test = np.asanyarray(test[['CSw']])\ny_test",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.77327 ],\n       [0.766865],\n       [0.681677]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": "#### 4. Cost Function",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def compute_cost(X, y, w, b):\n    '''\n    compute cost\n    Args:\n      X (ndarray(m, n)) : Variables, m samples with n features\n      y (ndarray(m))    : m target values\n      w (ndarray(n,))   : n features' parameters\n      b (scalar)        : parameter\n\n    Returns:\n      cost (scalar)     : cost (2* average of squared error)\n    '''\n    m = X.shape[0]\n    cost = 0.0\n    for i in range(m):\n        f_wb = np.dot(X[i], w) + b\n        cost = cost + (f_wb - y[i])**2\n\n    cost = cost/2/m\n    return cost",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "#### 5. Compute gradient",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def compute_gradient(X, y, w, b):\n    '''\n    compute gradient descent: define dj_dw and dj_db \n    Args:\n      X (ndarray(m, n)) : Variables, m samples with n features\n      y (ndarray(m))    : m target values\n      w (ndarray(n,))   : n features' parameters\n      b (scalar)        : parameter\n\n    Returns:\n      dj_dw, dj_db \n    '''\n    # sample size and parameter size\n    m = X.shape[0]\n    n = X.shape[1]\n\n    # define dj_dw and dj_db\n    dj_dw = np.zeros(n)\n    dj_db = 0.\n\n    # gradient descent functions\n    for i in range(m):\n        diff = np.dot(X[i], w) + b - y[i]\n        dj_db = dj_db + diff/m\n\n        for j in range(n):\n            # at certain i,j dj_dw[j] = :\n            dj_dw[j] = dj_dw[j] + diff * X[i,j] / m\n           \n    return dj_dw, dj_db\n            ",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "# compute and display gradient\n# test with X, y\n# first_dj_dw, first_dj_db = compute_gradient(X, y, w_init, b_init)\n# print('initial dj_dw is: ',first_dj_dw)\n# print('initial dj_db is: ',first_dj_db)",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "#### 6. Gradient Descent with Multiple Variables",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n    \"\"\"\n    Performs batch gradient descent to learn w and b. Updates w and b by taking \n    num_iters gradient steps with learning rate alpha\n    \n    Args:\n      X (ndarray (m,n))   : Data, m examples with n features\n      y (ndarray (m,))    : target values\n      w_in (ndarray (n,)) : initial model parameters  \n      b_in (scalar)       : initial model parameter\n      cost_function       : function to compute cost\n      gradient_function   : function to compute the gradient\n      alpha (float)       : Learning rate\n      num_iters (int)     : number of iterations to run gradient descent\n      \n    Returns:\n      w (ndarray (n,)) : Updated values of parameters \n      b (scalar)       : Updated value of parameter \n      \"\"\"\n    \n    # An array to store cost J and w's at each iteration primarily for graphing later\n    J_history = []\n    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n    b = b_in\n    \n    for i in range(num_iters):\n\n        # Calculate the gradient and update the parameters\n        dj_dw,dj_db = gradient_function(X, y, w, b)   ##None\n\n        # Update Parameters using w, b, alpha and gradient\n        w = w - alpha * dj_dw               ##None\n        b = b - alpha * dj_db               ##None\n      \n        # Save cost J at each iteration\n        if i<100000:      # prevent resource exhaustion \n            J_history.append( cost_function(X, y, w, b))\n        if i% math.ceil(num_iters / 10) == 0: \n            print(\"Iteration and cost are \",i, J_history[-1]) # [-1] last J_history\n \n    return w, b, J_history #return final w,b and J history for graphing",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "# initialize parameters\nn = X_train.shape[1]\ninitial_w = np.zeros(n)\ninitial_b = 0.\n\n# some gradient descent settings\niterations = 10000\nalpha = 5.0e-1\n\n# run gradient descent \nw_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, compute_gradient, alpha, iterations)\nprint(\"b,w found by gradient descent: \",b_final,w_final)\n\nm,_ = X_test.shape\nfor i in range(m):\n    print(\"prediction: \",np.dot(X_test[i], w_final) + b_final, \"target value: \", y_test[i])",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-17-5402e573ce5e>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  dj_dw[j] = dj_dw[j] + diff * X[i,j] / m\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Iteration and cost are  0 [0.03339206]\nIteration and cost are  1000 [0.00047345]\nIteration and cost are  2000 [0.00047095]\nIteration and cost are  3000 [0.00047093]\nIteration and cost are  4000 [0.00047093]\nIteration and cost are  5000 [0.00047093]\nIteration and cost are  6000 [0.00047093]\nIteration and cost are  7000 [0.00047093]\nIteration and cost are  8000 [0.00047093]\nIteration and cost are  9000 [0.00047093]\nb,w found by gradient descent:  [0.47851671] [ 0.54837035 -0.03492684]\nprediction:  [0.79602105] target value:  [0.77327]\nprediction:  [0.75620107] target value:  [0.766865]\nprediction:  [0.69304051] target value:  [0.681677]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    }
  ]
}